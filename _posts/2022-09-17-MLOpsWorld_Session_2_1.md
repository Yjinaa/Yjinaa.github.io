---
title: MLOps World Conference _ Supporting Sales Forecasting at Scale for Canada’s Largest Grocery Store (1)
date: 2022-09-17 00:14:00 +0300
description: MLOps World 컨퍼런스에서 들었던 세션 중 캐나다 식료품점의 대규모 판매 예측에 대한 발표한 세션을 정리해보았습니다.
img:  # Add image post (optional)
fig-caption: # Add figcaption (optional)
tags: [conference] # add tag
use_math: true
categories:
  - Event Recaps
sidebar:
    nav: "blog"
---

## **세션 소개**

&#160;&#160;MLOps World 컨퍼런스에서 들었던 세션 중 하나로, 캐나다에서 가장 큰 식료품점의 대규모 판매 예측에 대해 소개한 세션입니다. Loblaws의 Cheng Chen, Mefta Sadat에 의해 진행되었습니다. 정리 겸 공유차 글을 씁니다. 내용이 상당히 길어서, 몇 편에 나누어 글을 작성해보겠습니다.

​                                       

​                                         

### About Loblaws

&#160;&#160; Loblaws는 캐나다에서 가장 큰 식료품 체인 중 하나입니다. 약간의 차이는 있지만, 우리나라의 이마트와 유사하다고 보시면 될 것 같습니다. 약 2200개의 매장이 존재하고, 하루 온라인 매출은 약 $5M (약 50억) 입니다. 더불어 하루 온라인 주문 건수는 35,000건에 달합니다. 따라서 Loblaws는 하루 약 10억건의 아이템 추천에 대한 요청을 받습니다. 따라서 검색 및 추천부터 시작해서 재고 가용성과 판매 예측까지 다양한 사례에서 ML을 적용할 수 있습니다. 누군가 온라인 주문을 하면 picker가 매장에서 주문을 일괄 피킹할 때 발생하는 운영 문제들과 같은 사례를 해결해야합니다. 그래서 ML로 Loblaws의 서로 다른 비즈니스 문제들을 해결하는 use case들이 상당히 많습니다.

​                      

### 판매 예측 문제 개요

- **Store-day** , 일별 예측 문제
  - 예 : 지금부터 앞으로 7일간 특정 매장에서 몇 건의 온라인 주문들을 받게 되겠는가?
- **Store-item-hour**, 아이템별 시간별 예측 문제
  - 예 : 지금부터 48시간 동안 특정 매장에서 몇 개의 사과가 팔리겠는가?

​                      

자, 식료품 매장에서 발생할 세일즈들에 대해 예측한다고 생각해봅시다. 여기에는 다양한 레벨이 있을 수 있습니다.

예를 들어, 가장 먼저 앞으로 7일간 온라인 주문이 얼마나 들어올 것이며, 그를 위해서 가장 가능한 빠른 시간 안에 어떻게 인력 배치를 해서 고객의 주문을 충족할것인지를 생각해볼 수 있습니다.

일별이 아닌 특정 시간으로도 생각해볼 수 있습니다. 예를 들면 다음 48시간 동안 사과가 얼마나 팔릴 것인가 등입니다. 앞서 언급했듯이 Loblaw는 캐나다에 약 2000개가 넘는 매장이 존재합니다. 모든 매장에 대해 모델을 생성하는 경우를 생각해봅시다. 수백개의 모델을 생성/훈련시키고 모니터링하는 것은 굉장히 어려운 일입니다.

이러한 예측들을 처리 할 때 발생하는 또 다른 문제는 바로 이러한 ML 워크플로우가 마비되는 것입니다. Loblaw 팀이 모델들을 돌리는 데 필요로 하는 컴퓨팅 리소스는 굉장히 방대합니다. 따라서 ML 플랫폼을 필요로 했는데요, 다음 섹션에서 scalability 문제 해결을 도와준 플랫폼에 대해 이야기해보겠습니다.

​                         

### 왜 Vertex AI인가?

-  ML workflow의 모든 단계를 위한 도구
- 파이프라인
- 트레이닝
- ML 메타데이터
- Feature store
- Model 배포

​                           

&#160;&#160;&#160;&#160;Loblaw는 현재 구글 클라우드 플랫폼을 사용하고 있고, Vertex AI라는 MLOps 플랫폼을 사용하고 있습니다. Vertex AI는 ML 워크 플로우 모든 단계의 완전한 솔루션을 제공합니다. 현재 Loblaws의 플랫폼은 하이브리드 플랫폼이라고 할 수 있는데, 대부분은 Vertex AI를 통해 관리하지만 일부는 여전히 다른 오픈 소스 도구들도 사용하고 있기 때문입니다.

이제 ML의 각기 다른 스텝에서 Loblaws 팀이 어떠한 다른 경험들을 겪어왔는지를 보겠습니다. Vertex의 파이프라인을 사용하기 전에는 ML 파이프라인을 돌리기 위해 Airflow를 사용했습니다.

Airflow에서는 여러 어려움이 있었습니다. 예를 들어 서로 다른 component에 대한 lineage를 확인할 수 없었고, scaling에 한계점이 존재했습니다. 그러나 Vertex는 서버리스 플랫폼으로, 함께 사용하면 이 어려움을 모두 해결할 수 있었습니다.

다음 파트는 트레이닝 입니다. 초반에는 쿠버네티스에서 트레이닝을 시키기 시작했습니다. 그래서 데이터 과학 그룹을 위한 쿠버네티스 노트북을 사용하곤 했으나 곧 몇가지 걸림돌을 만나게 되는데, 특히 작업을 스케줄링 하는 것에 대한 어려움을 직면하게 되었습니다. 매 시간 작업량을 스케줄링해야하고 여러 팀들이 이 플랫폼을 사용하다보니 동시에 GPS에 접근을 시도하는 등의 몇몇 이슈들이 발생하기 시작했습니다. 이러한 어려움들은 Vertex training을 사용하니 해결되었는데요, Vertex training은 팀이 원하면 어느 때든간에 리소스를 활용하거나 요청하여 작업량을 서버리스 Vertex에 올릴 수 있게끔 해주었기 때문입니다.

다음 도구는 ML Metadata 서비스입니다. Loblaws는 ML flow를 두고 어떤 서비스가 더 나은지 함께 검증했습니다. ML flow는 실험 메타데이터와 모든 것을 추적하는 아주 아주 강력한 도구입니다. 그러나 Vertex ML metadata 서비스는 ML flow가 제공하지 않은 몇가지 피처들을 더 제공했습니다. 예를 들어, ML flow는 rule 기반 접근 컨트롤 기능이 없어 서로 다른 ML 실험들을 정리할 좋은 방법이 없었습니다. 그래서 ML 서버에 남아있으면서 몇몇 리소스를 요청할 수 있도록 해야했습니다. 반면에, Vertex는 관리된 솔루션 메타데이터 서비스를 가지고 있어 그럴 필요가 없었습니다.

다음 도구는 feature store 입니다. 이것은 ML pipeline에 또다른 중요한 요소입니다. Vertex의 feature store를 통해 효율적으로 Loblaws의 피처들을 정리할 수 있도록 도와주는 UI가 존재했기 때문에 쉽고 빠르게 피처들을 찾을 수 있었고, 더불어 라벨링도 쉽게 할 수 있었습니다. 또 다른 이점은 피처 수집 작업을 일괄적으로 할 수 있고 확장성이 높으며, low latency의 무료 온라인 feature store을 제공한다는 것입니다.

그리고 마지막으로, 모델 배포입니다. 이것은 ML 라이프 사이클에서 중요한 또다른 요소인데요, 배포에서 Vertex는 endpoints를 제공하지만 Loblaws는 다른 오픈소스를 사용합니다. 바로 Seldon입니다. Seldon은 새로운 피처들을 실험할 때 매우 유용한 AB 테스트와 같은 강력한 기능을 제공합니다.

​                                    

### MLOps 아키텍처

&#160;&#160;&#160;&#160;이제 Loblaws가 빌드한 MLOps platform에 대해 알아보고 이 플랫폼이 어떻게 대규모 판매 예측에 도움이 되었는지 알아보겠습니다. 3년 전, Loblaws는 ML이 모든 제품의 핵심 구성 요소인 단계에 있었습니다. 따라서 데이터 사이언스팀과 협력하여 커스텀된 솔루션을 생각해냈고 팀과 제품이 성장했지만 이러한 접근법은 확장성이 매우 낮았습니다. 그래서 Loblaws 팀은 ML 플랫폼이라는 개념을 고안하게 되었습니다. 

이 ML 플랫폼을 보면, 각각의 일반적인 ML pipeline 단계를 볼 수 있습니다. 데이터 준비와 피처 엔지니어링에서 시작해서 모델 트레이닝, 레지스트리, 그리고 매니지먼트가 있고 마지막으로 모델 배포 단계와 모델의 퍼포먼스를 보는 observing 단계가 존재합니다. 그리고 이 모든 트레이닝은 상단의 apache airflow에 의해 조정됩니다.

Loblaws는 분석에서 가져온 데이터를 캡처하여 파이프라인의 끝에서 모델 성능에 대한 드리프트를 모니터링합니다. 운영 환경에서 어떻게 작동하는지, 추천이 클릭되고 있는지, 유저가 추천을 사용하고 있는지, 이 모든 것들이 로그를 통해 캡쳐되고 있는지, 대시보드를 보는 것에 익숙해지고 있는지 등입니다. 그리고 Loblaws는 대시보드에서 쉽게 드리프트와 트리거를 판별하고, 이들이 발생하는 것을 억제하거나 팀 내 누군가가 지켜보고 있게 할 수 있었습니다.

Loblaws가 드리프트를 감지하는 또 다른 단계는 바로 피처 값 레벨입니다. Vertex는 값을 모니터링할 수 있게 하는 강력한 피처들을 제공합니다. 매 포인트마다 피처 값의 스냅샷을 찍고 피처값의 분포를 비교합니다. 만일 피처값들이 트레이닝 때와 다르다면, 팀에서 쉽게 그것을 잡아낼 수 있습니다. 따라서 ML 플랫폼의 목표는 데이터 사이언티스트 팀이 탐색적 데이터 분석에서 운영 환경으로 신속하게 이동하는 것을 돕는 것입니다. 또한 운영 환경에서 Loblaws의 목표는 그들의 시스템이 어떻게 작동하는지 모니터링하고 관찰하는 것입니다.

​                            

​                             

## 마치면서

&#160;&#160;&#160;&#160;상당히 많은 내용을 담았다고 생각했는데, 막상 글을 작성해보니 짧게 느껴지네요. 영어로 된 영상을 기반으로 작성하는 글이라 시간이 두배로 드는 것 같습니다. 😅 역시 영어의 길은 멀고도 험합니다.. 이번 글은 최대한 3편 이내로 끝내보려고 합니다. 제가 개인적으로 번역/정리하는 글이라 오역이나 어색한 부분이 있을 수 있습니다. 혹시 잘못된 부분을 발견하셨다면 말씀주시면 감사하겠습니다. 읽어주셔서 감사합니다. 😄

​        

​                      

​                      













​                              

​                                  

​                                                                               

​              

​                                   

​                                   

​                                   
