---
layout: post
title: Collision Conference _ 에릭 슈미트가 말하는 AI와 우리 인간의 미래
date: 2022-08-07 02:33:00 +0300
description: 콜리전 세션 하나를 정리해보았습니다.
img:  # Add image post (optional)
fig-caption: # Add figcaption (optional)
tags: [gueltto,writing,post,conference] # add tag
use_math: true
---

## **세션 소개**

&#160;&#160;콜리전 컨퍼런스에서 들었던 세션 중 하나로, 인상깊게 들어서 한 번 정리해보고 싶었던 세션입니다. 정리 겸 공유차 글을 올려봅니다. 이 세션은 사회자가 질문하고 에릭 슈미트가 답하는 인터뷰 방식으로 진행되었습니다.

​                                       

​                                         

### AI는 Sentient 한가?

&#160;&#160;구글에는 LaMDA라는 대화가 가능한 실험적인 시스템이 있습니다. 소름돋을 정도로 지식을 갖춘 다른 사람과 이야기 하는 느낌이 듭니다. sentient 하지는 않을지라도, 확실히 유용하고 강력합니다.

​                                            

### 향후 5년은 어떨까?

&#160;&#160;10 년 전 가장 우리가 크게 생각했던 주제를 본다면 바로 Imaging, 특히 이미지와 다른 많은 것들을 통한 vision이 인간보다 컴퓨터에서 더 나을 것이라는 사실이었습니다. 즉, 의사들이 컴퓨터를 사용한다면 더 좋은 실력을 뒷받침 할 수 있고, 자동차는 스스로 운전을 할 수 있다는 그런 것들이 바로 직전의 사이클이었습니다. 현재의 사이클은 두 가지로 구성되어 있는데, 하나는 과학자들이 다음의 사실에 집중하기 시작했다는 것입니다. 바로 input과 output이 있을 때 어떻게 input이 output을 만들어내느냐, 엄밀히 말하면 이것은 높은 복잡성의 다차원 공간이지만, 더 낮은 수준의 복잡성으로 이해하고 싶어합니다. 이러한 기술적 수준에서의 발견들은 생물학, 화학, 의학, 약물치료 등과 같은 것들에 엄청난 이익을 가져다주고 있습니다. 또 다른 하나는 large language model 입니다. GPT-3로 시작된 large language model들은 대화식이며 그간 나왔던 어떤 모델들과도 다릅니다. 왜냐하면 우리가 할 일은 그 모델이 가능한 모든 것을 배우는 것을 보는 것 뿐이기 때문이죠. 그러고 나서 모델이 무엇을 알고 있는지 알아내기만 하면 됩니다. 구글의 paLM 시스템은 실제로 특정한 예를 주지 않아도 컴퓨터 언어를 다른 언어로 번역할 수 있습니다. 딥러닝 모델들이 얻고 있는 내재적인 지식 표현은 매우 강력합니다. 이렇게 수십억 달러가 계속 투자된다면, 텍스트에서 음성 및 비디오로 매끄럽게 이동하며 동일하게 취급되는 것도 보게 될 수 있을 것입니다. 두 번째는 generative design 입니다. 우리가 무언가를 연구하고, 기능을 예측할 수 있다면 새로운 것을 생성할 수도 있습니다. 그 예로 DALL-E 2를 들 수 있는데요, 언어로 원하는 것을 묘사해주면 그 이미지를 그려줍니다. 에릭이 가장 좋아하는 예는, "Show me a picture of two baby dinosaurs going up the steps into kindergarten on their first day." 라고 합니다. 이러한 명령을 내리면, 두 마리의 작은 아기 공룡이 웃으며 백팩을 매고 유치원 계단을 올라가고 있는 그림을 보여줍니다. 여기서 주목할만한 점은 바로 '웃으며' 입니다. 모델은 공룡들이 첫 날 학교를 가면서 웃는다는 것을 어떻게 알 수 있었을까요? 어떻게든 학습한 것입니다. 아주 강력하다고 할 수 있죠. 

또한 에릭은 향후 5년 내로 두 가지 일을 할 수 있을 것이라 확신한다고 이야기했습니다. 바로 하나는 AI Second Self 입니다. 이것은 말 그대로 두번째 자기 자신을 말합니다. 당신을 보고, 당신이 훈련시킬 수 있고, 당신처럼 말할 수 있으며 때로는 어떠한 특정한 상황과 제한 안에서 당신을 대표할 수도 있습니다. 두 번째는 지금보다 더 강력한 AI assistant 입니다. 가령 이 사람은 좋은 사람입니다, 이 사람은 나쁜 사람입니다, 당신은 오늘 캐나다에 가야합니다, 이것은 말하면 안됩니다, 왜냐하면 좋지 않은 이야기이기 때문이지요 와 같은 말을 해 줄 수 있을 정도의 강력한 assistant를 만날 수 있습니다. 

​                                      

### 걱정되는 문제들

&#160;&#160;&#160;&#160;사람들은 대부분 시스템에 문제가 있다고 생각합니다. 시스템은 망가지기 쉽고, 시간 개념이 없으며, 쉽게 공격받을 수 있다 등의 문제들입니다. 이러한 것들이 해결된다면 인간과 비슷한 시스템을 얻을 수 있을 것입니다. 그러나, 여기서 중요한 것이 있습니다. 인간과 비슷하다는 것이 정말 또래의 지능을 가진 인간의 정체성과 유사하다는 것은 아닙니다. 시스템이 인간의 지능을 모방하는 것은 아닙니다. 예를 들어 제가 어떠한 사람을 서로 오래 알고 지낸다면, 저는 대략 그 사람이 어떻게 생각하는지 짐작할 수 있을 것입니다. 인간이고, 아침엔 일어나고, 학교를 다녔거나 다니고 있을 것이고, 한국어로 얘기하고 등등을 상상할 수 있겠죠. 그러나 이 쪽에 컴퓨터 한 대가 있다고 생각해봅시다. 저 컴퓨터가 갑자기 좋지 않은 쪽으로 행동할 수도 있고, 아직 아무도 보지 못한 불시의 새로운 행동(emergent behavior)을 할 수도 있습니다. 그리고 이러한 것들은 아무도 예측할 수 없습니다. 왜냐하면 끊임없이 학습하기 때문입니다. 만약 이 모델들이 구조적으로 잘못된 것을 학습한다면 어떤 일이 일어날까요? 그것 또한 아무도 알 수 없습니다. 

또한 시스템이 인간이 경험하는 방식을 바꿀 것이라는 것도 또 하나의 문제입니다. 에릭은 모든 사람들이 특정 쟁점에 관해 소셜 미디어가 어떻게 무기화 되는지에 대해 이해하고 있지는 않는 것 같다고 말합니다. 또한 만일 누군가의 가장 친한 친구가 사람이 아닌 컴퓨터일 때, 혹은 특히 아이들이 컴퓨터를 사용하다가 인종 차별, 학대, 거짓과 같은 것들을 배울 때 아이들은 그것들을 부모에게 말하지 않습니다. 부모 또한 고쳐줄 기회 없이 그저 컴퓨터 사용을 금지하는 데에 그칩니다. 이러한 방식으로, 큰 스케일로 우리가 일상을 경험하는 방식이 바뀔 수 있습니다. 만일 위에서 언급한 아무도 예상치 못한 불시의 행동 또는 generative design으로 인해 발생하는 문제라면 해결이 굉장히 까다로워질 가능성이 높습니다. 우리는 모델이 무엇을 할 지 모르기 때문에 편집증적으로 모든 것을 걱정하고 두려워하게 될 수 있을 것입니다. 에릭은 이러한 것들이 나중에 쟁점이 될 것이라고 생각하며, 현재 중점을 두고 걱정하는 문제라고 말했습니다. 

​                                  

### 청중들에게 하고 싶은 말

&#160;&#160;위의 문제들을 떠나 긍정적인 측면으로 봤을 때, 비즈니스를 할 때 있어서 알고리즘에 학습을 사용하는 것은 필수적입니다. 에릭은 AI를 학습하는 시스템이라고 정의했습니다. 그만큼 학습은 중요합니다. 만일 당신이 구축한 시스템에 학습 기능이 없다면, 동일한 일을 하는 시스템이면서 동시에 학습 알고리즘을 탑재한 누군가에게 패배할 것입니다. 그리고 또 한가지는 대형 언어 모델에 관해 덧붙이자면, 만일 당신이 스타트업이나 기술 플랫폼에서 있다면, 새로운 것을 생성하는 generative design 시스템의 경우 트랜스포머 또는 다른 거대 유명 모델을 기반으로 합니다. 이를 위해서 50명으로 구성된 팀이 필요하다거나 하지는 않습니다. 이 모델들은 오픈 소스이기때문에 어떤 형태로든 이용할 수 있습니다. 또한 large language model들은 fine tuning이 가능합니다. 즉, 당신이 필요로 하는 분야에 맞춰 튜닝할 수 있습니다. 의학에서 뭔가를 하려고 노력한다면, 의학에 맞게 잘 조정하면 됩니다. 이 모든 것을 수행한다면, 이 놀라운 혁신의 향후 3~4년동안 매우 강력한 위치를 차지하게 될 수 있을 것입니다. 

​                                   

​                                              

## 마치면서

&#160;&#160; 사실 이 세션이 20분 정도의 그리 길지 않은 세션인데, 번역하고 글을 쓰는데는 몇 배의 시간이 걸렸습니다. 제공되는 다시보기 영상에 자막이 없어서 이해하지 못한 부분은 혹시라도 잘못 전달될까 걱정되어 건너뛰기도 했습니다. 최대한 많은 부분을 전달드리고 싶었는데 조금 아쉽네요.. 

AI는 생각보다 정말 빠르게 변화하고 있는 것 같습니다. 위에서 언급한대로 자율주행 자동차, 사람처럼 인터랙티브한 대화가 가능한 모델 등이 이미 전부 나왔고 또 개발중에 있습니다. 특히 대화에서 언급된 '불시의 행동(emergent behavior)'에 대해 생각해보게 되었습니다. 물론 새로운 것을 아웃풋으로 낼 수는 있지만 학습할 때 사용한 인풋 데이터의 어느 정도의 틀을 가지고 아웃풋으로 나온다.. 라는 생각을 가지고 있었는데 위의 generative design과 공룡의 웃음 얘기를 들으니 생각이 완전히 바뀌었습니다. 더 경각심을 가지고 다뤄봐야 할 문제인 것 같습니다. 

컨퍼런스 당시 세션을 들었을 때는 약간 후루룩 지나간 느낌이 컸는데, 이렇게 다시 들으며 정리하니 복기도 되고 놓친 내용도 다시 캐치할 수 있어 좋았습니다. 앞으로도 하나씩 정리하며 복습하는 시간을 가져야겠습니다.

읽어주셔서 감사합니다.

​              

​                                   

​                                   

​                                   
